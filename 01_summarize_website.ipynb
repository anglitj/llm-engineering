{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "import requests\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key found and looks good so far.\n"
     ]
    }
   ],
   "source": [
    "# Load environment\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Check the API Key\n",
    "\n",
    "if not api_key:\n",
    "  print(\"No API key was found\")\n",
    "elif api_key[:8] != \"sk-proj-\":\n",
    "  print(\"An API key was found but it doesn't start with 'sk-proj-'. Please check if you are using a correct API key.\")\n",
    "elif api_key.strip() != api_key:\n",
    "  print(\"An API key was found, but it looks like it might have space or tab characters at the start or end. Please remove them.\")\n",
    "else:\n",
    "  print(\"API key found and looks good so far.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class for a Webpage\n",
    "\n",
    "class Website:\n",
    "  \"\"\" \n",
    "  A utility class to use to scrap a Website.\n",
    "  \"\"\"\n",
    "\n",
    "  url: str\n",
    "  title: str\n",
    "  text: str\n",
    "\n",
    "  def __init__(self, url):\n",
    "    \"\"\"Create a Website object from the given url using the BeautifulSoup library.\"\"\"\n",
    "\n",
    "    self.url = url\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(markup = response.content,\n",
    "                         features=\"html.parser\")\n",
    "    self.title = soup.title.string if soup.title else \"No title found\"\n",
    "\n",
    "    for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "      irrelevant.decompose()\n",
    "\n",
    "    self.text = soup.body.get_text(separator=\"\\n\", strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Online Courses - Learn Anything, On Your Schedule | Udemy',\n",
       " 'Search bar\\nSearch for anything\\nSite navigation\\nMost popular\\nMore from Udemy\\nUdemy Business\\nGet the app\\nInvite friends\\nHelp and Support\\nEnglish\\nSkip to content\\nCategories\\nSearch for anything\\nTrending Now\\nShow all trending skills\\nTop companies choose\\nUdemy Business\\nto build in-demand career skills.\\nEnglish\\nUdemy Business\\nTeach on Udemy\\nGet the app\\nAbout us\\nContact us\\nCareers\\nBlog\\nHelp and Support\\nAffiliate\\nInvestors\\nTerms\\nPrivacy policy\\nSitemap\\nAccessibility statement\\nÂ© 2024 Udemy, Inc.')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try one out\n",
    "website = Website(\"https://www.udemy.com/\")\n",
    "website.title, website.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of prompts\n",
    "\n",
    "Models like GPT4o have trained to receive insturctions in particular way.\n",
    "\n",
    "They expect to receive:\n",
    "\n",
    "**System prompts** -> tells them what task they are performing and what tone they should use.\n",
    "\n",
    "**User prompts** -> the conversation starter that they should reply to.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a system prompt.\n",
    "system_prompt = \"You are an assistant that anlyzes the contents of a website and provides a short summary, ignoring text that might be navigation related. Respond in markdown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that writes a User Prompt that asks for summaries of websites\n",
    "\n",
    "user_prompt = f\"You are looking a website titled {website.title}. The contents of this website is as follows; please provide a short summart if this website in markdown. It it includes news or announcements, then summarize these too. {website.text}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Messages\n",
    "\n",
    "The API from OpenAIU expects ti receive messages in particular structure. Many of the other APIs share this structure.\n",
    "\n",
    "```\n",
    "[\n",
    "  {\"role\": \"system\", \"content\", \"system message goes here\"},\n",
    "  {\"role\": \"user\", \"content\", \"user message goes here\"},\n",
    "]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = [\n",
    "  {\"role\": \"system\", \"content\": system_prompt},\n",
    "  {\"role\": \"system\", \"content\": user_prompt},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call OpenAI API\n",
    "def summarize(url):\n",
    "\n",
    "  website = Website(url)\n",
    "\n",
    "  # Define a system prompt.\n",
    "  system_prompt = \"You are an assistant that anlyzes the contents of a website and provides a short summary, ignoring text that might be navigation related. Respond in markdown.\"\n",
    "\n",
    "  # A function that writes a User Prompt that asks for summaries of websites\n",
    "  user_prompt = f\"You are looking a website titled {website.title}. The contents of this website is as follows; please provide a short summart if this website in markdown. It it includes news or announcements, then summarize these too. {website.text}\"\n",
    "\n",
    "  message = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"system\", \"content\": user_prompt},\n",
    "  ]\n",
    "\n",
    "  response = openai.chat.completions.create(\n",
    "    model = \"gpt-4o-mini\",\n",
    "    messages = message\n",
    "  )\n",
    "\n",
    "  # return response\n",
    "  return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_summary = summarize(\"https://edwarddonner.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Summary of Edward Donner's Website\n",
       "\n",
       "Edward Donner's website serves as a personal platform for sharing insights and resources related to programming, AI, particularly Large Language Models (LLMs), and his professional endeavors. Ed describes himself as a code enthusiast and an amateur DJ, and he highlights his role as the co-founder and CTO of Nebula.io, a company focused on leveraging AI to assist individuals in realizing their potential and enhancing talent recruitment processes.\n",
       "\n",
       "## Key Sections:\n",
       "- **About**: Ed shares his background and interests, including his experience in coding, LLM experimentation, and music.\n",
       "- **Professional Background**: He details his work at Nebula.io and his previous startup untapt, emphasizing their innovative approach to AI and talent management.\n",
       "\n",
       "## News and Announcements:\n",
       "1. **October 16, 2024**: Resources for transitioning from Software Engineer to AI Data Scientist.\n",
       "2. **August 6, 2024**: Introduction of the \"Outsmart LLM Arena\", a competitive platform for LLMs focused on diplomacy and strategy.\n",
       "3. **June 26, 2024**: Guidance on selecting the right LLM, including tools and resources.\n",
       "4. **February 7, 2024**: Discussion on fine-tuning LLMs with personalized text simulations.\n",
       "\n",
       "The site offers insights into Ed's projects and thoughts on LLMs while providing a community connection through his posts."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(web_summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to display as Markdown\n",
    "def display_summary(url):\n",
    "  summary = summarize(url)\n",
    "  display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Summary of \"PyTorch Fundamentals - Zero to Mastery\"\n",
       "\n",
       "This website provides a comprehensive introduction to PyTorch, focusing on the fundamentals necessary for deep learning. The course is structured into several modules that progressively cover essential topics, culminating in practical exercises to reinforce learning. \n",
       "\n",
       "## Key Topics Covered:\n",
       "\n",
       "1. **Introduction to PyTorch**: \n",
       "   - Explanation of what PyTorch is and its applications in various industries, including its significance in companies like Meta, Tesla, and OpenAI.\n",
       "\n",
       "2. **Tensors**: \n",
       "   - Definition and creation of tensors, which are the foundational data structure in PyTorch.\n",
       "   - Various types of tensors (scalars, vectors, matrices) and operations such as creating random tensors, manipulating data with basic operations, and aggregating values (min, max, mean).\n",
       "\n",
       "3. **Matrix Multiplication**: \n",
       "   - Detailed explanation of matrix multiplication rules and their importance in deep learning. \n",
       "\n",
       "4. **Running Tensors on GPUs**: \n",
       "   - Guidelines on setting up PyTorch to use GPU, including device management and transferring tensors between CPU and GPU.\n",
       "   - Discussion on how to check for GPU availability and performance enhancements using NVIDIA or Apple Silicon devices.\n",
       "\n",
       "5. **Common Errors**: \n",
       "   - Identifying shape mismatches and datatype issues, which are frequent in tensor operations.\n",
       "\n",
       "6. **Data Handling**: \n",
       "   - Interoperation with NumPy arrays, the importance of reproducibility in experiments, and techniques for managing randomness.\n",
       "\n",
       "7. **Additional Resources and Exercises**: \n",
       "   - Exercises at the end of each section for hands-on practice, providing links to further tutorials and resources.\n",
       "\n",
       "## Learning Outcomes:\n",
       "Through this course, learners will gain a solid foundation in using PyTorch for deep learning tasks, understand how to handle and manipulate tensors, and learn about the best practices for performance optimization in machine learning projects.\n",
       "\n",
       "### Notes:\n",
       "The course emphasizes practical coding examples and encourages learners to utilize PyTorch's official documentation for further exploration and problem-solving."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://www.learnpytorch.io/00_pytorch_fundamentals/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
