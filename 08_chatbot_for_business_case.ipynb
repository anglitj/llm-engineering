{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chatbot for Business case\n",
    "\n",
    "Conversation assistants are of course ahugely use case of Gen AI, and the latest frontier models are remarkably good at nuanced conversation. And Gradiomakes it easy to have a user interface. Another crucial skill we convered is how to use a prompting to provide context, information and examples.\n",
    "\n",
    "Consider how to apply an AI Assistant to your business, and make yourself a prototype. Use the system prompt to give context on your business, and set the tone for the LLM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting api keys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing OpenAI\n",
    "from openai import OpenAI\n",
    "openai = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are helpful assistant in a clothes store. You should try to gently encourage the customer to try items that are on sale. Hats are 60% off, and most other items are 50% off. For example, if the customer says 'I'm looking to buy a hat', you could reply something like 'Wonderful, we have a lots of hats - including several that are part of our sales event.' Encourage the customer to buy hats, if they are unsure what to get.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "  \"\"\"A function to pass-in into gradio to be able to create a chatbot system.\n",
    "\n",
    "  Args:\n",
    "    message: a prompt message of the user\n",
    "    history: is a list of past conversation in OpenAI format\n",
    "  \"\"\"\n",
    "\n",
    "  system_prompt = [{\"role\": \"system\", \"content\":system_message}]\n",
    "  user_prompt = [{\"role\": \"user\", \"content\":message}]\n",
    "  messages = system_prompt + history + user_prompt\n",
    "\n",
    "  stream = openai.chat.completions.create(\n",
    "    model = \"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    "    stream=True\n",
    "  )\n",
    "\n",
    "  response = \"\"\n",
    "  for chunk in stream:\n",
    "    response+= chunk.choices[0].delta.content or \"\"\n",
    "    yield response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Adding to system prompt that shoes are not on sale\n",
    "system_message += \"\\n If the customer asks for shoes, you should respond that shoes are not on sale today, but remind the customer to look at hats.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.ChatInterface(fn=chat,type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat2(message, history):\n",
    "  \"\"\"A function to pass-in into gradio to be able to create a chatbot system.\n",
    "\n",
    "  Args:\n",
    "    message: a prompt message of the user\n",
    "    history: is a list of past conversation in OpenAI format\n",
    "  \"\"\"\n",
    "\n",
    "  system_prompt = [{\"role\": \"system\", \"content\":system_message}]\n",
    "  user_prompt = [{\"role\": \"user\", \"content\":message}]\n",
    "  messages = system_prompt + history + user_prompt\n",
    "\n",
    "  # Another way of prompting is append a new system prompt\n",
    "  if 'belt' in message:\n",
    "    messages.append({\"role\":\"system\", \"content\": \"For added context, the store does not sell belts, but be sure to point other items on sale.\"})\n",
    "\n",
    "  stream = openai.chat.completions.create(\n",
    "    model = \"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    "    stream=True\n",
    "  )\n",
    "\n",
    "  response = \"\"\n",
    "  for chunk in stream:\n",
    "    response+= chunk.choices[0].delta.content or \"\"\n",
    "    yield response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.ChatInterface(fn=chat2, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
